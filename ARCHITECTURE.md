# Architecture D√©taill√©e du Pipeline

## Vue d'ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenWeather    ‚îÇ
‚îÇ      API        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP GET
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Python Script  ‚îÇ
‚îÇ  (Producer)     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Kafka Topic: weather-data
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Kafka Consumer ‚îÇ
‚îÇ   + MinIO SDK   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí S3/MinIO: bronze-layer/
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       (Parquet files)
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    PySpark      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí S3/MinIO: silver-layer/
‚îÇ  Transformations‚îÇ       (Cleaned Parquet)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Spark JDBC     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí PostgreSQL: weather_dw
‚îÇ   to Postgres   ‚îÇ       (gold_weather_*)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Power BI      ‚îÇ
‚îÇ   Dashboard     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Couches de Donn√©es (Medallion Architecture)

### ü•â Bronze Layer (Raw Data)
**Emplacement:** MinIO bucket `bronze-layer`  
**Format:** Parquet (compression Snappy)  
**Partitionnement:** `year=YYYY/month=MM/day=DD/`

**Caract√©ristiques:**
- Donn√©es brutes non modifi√©es depuis Kafka
- M√©tadonn√©es Kafka ajout√©es (partition, offset, timestamp)
- Idempotent (peut √™tre rejou√© sans duplication)
- R√©tention: 30 jours

**Exemple de structure:**
```
bronze-layer/
‚îú‚îÄ‚îÄ year=2024/
‚îÇ   ‚îî‚îÄ‚îÄ month=01/
‚îÇ       ‚îî‚îÄ‚îÄ day=15/
‚îÇ           ‚îú‚îÄ‚îÄ weather_20240115_120000_123456.parquet
‚îÇ           ‚îî‚îÄ‚îÄ weather_20240115_130000_789012.parquet
```

### ü•à Silver Layer (Cleaned Data)
**Emplacement:** MinIO bucket `silver-layer`  
**Format:** Parquet (compression Snappy)  
**Partitionnement:** `year=YYYY/month=MM/`

**Transformations appliqu√©es:**
- ‚úÖ Conversion des types de donn√©es (string ‚Üí timestamp)
- ‚úÖ Filtrage des valeurs nulles critiques
- ‚úÖ Filtrage des temp√©ratures aberrantes (-100¬∞C √† 60¬∞C)
- ‚úÖ D√©duplication (city, timestamp)
- ‚úÖ Ajout de colonnes d√©riv√©es (year, month, day, hour, etc.)
- ‚úÖ Calcul du score de qualit√© des donn√©es
- ‚úÖ Agr√©gations journali√®res et horaires

**Datasets:**
1. `weather_cleaned/` - Donn√©es d√©taill√©es nettoy√©es
2. `weather_daily_agg/` - Agr√©gations journali√®res
3. `weather_hourly_agg/` - Agr√©gations horaires

**R√©tention:** 90 jours

### ü•á Gold Layer (Business Data)
**Emplacement:** PostgreSQL database `weather_dw`  
**Format:** Tables relationnelles

**Tables:**

1. **gold_weather_detailed**
   - Donn√©es d√©taill√©es pr√™tes pour l'analyse
   - Index sur (city, timestamp)
   - Contrainte unique pour idempotence
   - ~50 colonnes incluant m√©triques et m√©tadonn√©es

2. **gold_weather_daily_aggregates**
   - Agr√©gations quotidiennes par ville
   - M√©triques: avg, min, max pour temp√©rature, humidit√©, etc.
   - Optimis√© pour les tendances √† long terme

3. **gold_weather_hourly_aggregates**
   - Agr√©gations horaires par ville
   - Optimis√© pour l'analyse intra-journali√®re

4. **pipeline_execution_log**
   - Tra√ßabilit√© de chaque ex√©cution
   - M√©triques de performance
   - Gestion des erreurs

**R√©tention:** 365 jours

## Flux de Donn√©es D√©taill√©

### 1. Ingestion (weather_producer.py)

```python
# Pseudo-code simplifi√©
for city in cities:
    raw_data = fetch_from_api(city)
    weather_data = parse_data(raw_data)
    send_to_kafka(weather_data)
```

**Fr√©quence:** Toutes les heures (configurable)  
**Volume:** ~5 villes √ó ~2 KB/message = ~10 KB/run  
**Gestion d'erreurs:** Retry automatique (3 tentatives)

### 2. Stockage Bronze (kafka_consumer_s3.py)

```python
# Pseudo-code simplifi√©
for message in kafka_consumer:
    buffer.append(message)
    
    if len(buffer) >= batch_size:
        df = pd.DataFrame(buffer)
        save_to_s3_as_parquet(df)
        commit_kafka_offset()  # Idempotence
        buffer.clear()
```

**Batch size:** 100 messages  
**Compression:** Gzip (Kafka) + Snappy (Parquet)  
**Idempotence:** Commit Kafka apr√®s sauvegarde r√©ussie

### 3. Processing Silver (silver_processor.py)

```python
# Pseudo-code simplifi√©
df = spark.read.parquet("s3://bronze-layer/")

# Nettoyage
df_clean = df \
    .filter(col("temperature").isNotNull()) \
    .filter(col("temperature").between(-100, 60)) \
    .dropDuplicates(["city", "timestamp"])

# Enrichissement
df_enriched = df_clean \
    .withColumn("year", year("timestamp")) \
    .withColumn("heat_index", calculate_heat_index())

# Agr√©gations
daily_agg = df_enriched \
    .groupBy("city", "year", "month", "day") \
    .agg(avg("temperature"), ...)

# Sauvegarde
df_enriched.write.parquet("s3://silver-layer/weather_cleaned/")
daily_agg.write.parquet("s3://silver-layer/weather_daily_agg/")
```

**Optimisations Spark:**
- Adaptive Query Execution (AQE)
- Partition coalescing
- Predicate pushdown
- Compression Snappy

### 4. Chargement Gold (gold_loader.py)

```python
# Pseudo-code simplifi√©
df = spark.read.parquet("s3://silver-layer/weather_cleaned/")

df.write \
    .jdbc(
        url=postgres_url,
        table="gold_weather_detailed",
        mode="append"  # Gestion des doublons par contrainte unique
    )
```

**Mode d'√©criture:** Append avec contrainte UNIQUE  
**Gestion des doublons:** PostgreSQL UNIQUE index  
**Batch size:** 1000 enregistrements

## Orchestration Airflow

### DAG: weather_pipeline

**Schedule:** `0 * * * *` (toutes les heures)  
**Max active runs:** 1 (√©vite les ex√©cutions concurrentes)

**T√¢ches:**

```
check_api
    ‚Üì
ingest_data
    ‚Üì
consume_to_s3
    ‚Üì
process_silver
    ‚Üì
load_gold
    ‚Üì
quality_check
    ‚Üì
notify_success
    ‚Üì
cleanup_old_data
```

**SLA:** 30 minutes par ex√©cution  
**Retries:** 3 avec d√©lai de 5 minutes  
**Timeout:** 2 heures

## Qualit√© des Donn√©es

### Checks automatiques

1. **Compl√©tude:**
   - Champs obligatoires: city, timestamp, temperature
   - Seuil d'acceptation: 90%

2. **Validit√©:**
   - Temp√©rature: -100¬∞C √† 60¬∞C
   - Humidit√©: 0% √† 100%
   - Timestamp: dans les 24h

3. **Unicit√©:**
   - Cl√©: (city, timestamp)
   - D√©duplication automatique

4. **Fra√Æcheur:**
   - Donn√©es < 2 heures recommand√©
   - Alerte si > 6 heures

### Score de qualit√©

Chaque enregistrement re√ßoit un score (0-100):
- 100: Tous les champs pr√©sents
- -10 par champ optionnel manquant

## Performance et Scalabilit√©

### Capacit√© actuelle
- **Ingestion:** ~100 messages/minute
- **Processing:** ~10 000 enregistrements/minute
- **Stockage:** ~1 GB/mois (5 villes)

### Scaling horizontal

**Kafka:**
- Augmenter le nombre de partitions
- Ajouter des consumers dans le m√™me groupe

**Spark:**
- Ajouter des workers
- Augmenter la m√©moire (executor/driver)

**PostgreSQL:**
- Partitionnement par date
- Read replicas pour Power BI

### Monitoring

**M√©triques cl√©s:**
1. Lag Kafka (offset retard)
2. Temps d'ex√©cution Spark
3. Taille des buckets S3
4. Nombre d'erreurs dans pipeline_execution_log

**Alertes:**
- √âchec de t√¢che Airflow ‚Üí Email
- Lag Kafka > 1000 ‚Üí Notification
- Espace disque < 20% ‚Üí Alerte

## S√©curit√©

### Secrets
- Cl√©s API dans variables d'environnement
- Credentials Kafka/MinIO/PostgreSQL dans `.env`
- Fernet key pour Airflow

### R√©seau
- Isolation par Docker network
- Ports expos√©s uniquement pour interfaces UI

### Donn√©es
- Pas de donn√©es sensibles (m√©t√©o publique)
- Logs structur√©s sans PII

## Maintenance

### Quotidienne
- V√©rifier les logs Airflow
- Monitorer les m√©triques

### Hebdomadaire
- Nettoyer les anciennes donn√©es (fonction `cleanup_old_data()`)
- V√©rifier l'espace disque

### Mensuelle
- Backup PostgreSQL
- Audit des performances
- Revue des erreurs r√©currentes

## √âvolutions Futures

### Court terme
- [ ] Alertes Slack/Teams
- [ ] Dashboard Grafana
- [ ] Tests d'int√©gration CI/CD

### Moyen terme
- [ ] Support multi-APIs (Weather, Finance, etc.)
- [ ] ML pour pr√©dictions m√©t√©o
- [ ] API REST pour requ√™ter les donn√©es

### Long terme
- [ ] Migration vers Kubernetes
- [ ] Data Lake (Delta Lake)
- [ ] Real-time streaming analytics
